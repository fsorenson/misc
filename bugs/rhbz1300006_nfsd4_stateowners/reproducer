nfs client system with kernel version prior to 2.6.32-395.el6

I can replicate this issue.  It is caused by actions on the nfs client side with older kernels (before 2.6.32-395.el6), but results in high nfsd4_stateowners usage on the nfs server.  Once allocated, the nfsd4_stateowners are never returned from the slab cache.  Over time, nfsd4_stateowners grows, and the objects are never deallocated, leading to memory exhaustion on the nfs server, making the system unusable.

The client behavior which caused runaway slab usage on the server side was addressed in bz800677, so nfs clients running kernel 2.6.32-395.el6 or more recent will not cause the issue.  However older Linux clients can still cause the issue, and there may be other clients which also have this bad behavior.


This particular reproducer causes the condition by attempting to append to a file to which the user does not have write permission.  This is done in a loop, with a new process created to attempt the append each time through the loop.  Although each open (using O_RDWR or O_WRONLY) attempt fails, a new slab object is allocated each time, and is never recycled.  Slab caches with millions of nfd4_stateowners allocated, occupying large portions of system memory have been observed, even on nfs servers without any files open over NFS (and on nfs servers which currently have no attached nfs clients).


steps to reproduce:

On nfs client machine (note kernel version before 2.6.32-395.el6 is required, as discussed above):
	mount server:/export /mnt/test -o vers=4
	echo foo > /mnt/test/test_file
	chown user1:user1 /mnt/test/test_file
	chmod 0644 /mnt/test/test_file
	su - user2 -c "/bin/bash -c 'while true ; do echo test >> /mnt/test/test_file 2>/dev/null ; done'"


on nfs server machine, watch nfsd4_stateowners increase:
	watch "grep nfsd4_stateowners /proc/slabinfo"
or
	# while true ; do d=$(date --rfc-3339=seconds) ; echo "$d  $(grep nfsd4_stateowners /proc/slabinfo)" ; sleep 2 ; done

nfsd4_stateowners 801279 801297    424    9    1 : tunables   54   27    8 : slabdata  89033  89033      0


The test_file is owned by user1, and the permissions do not allow write access by user2, so each time through the loop, the attempt to open and append to the file fails.  However, since the file open is attempted by a new process, the nfs client doesn't reuse the existing open state.


(there also appears to be a size-32 allocated as well, though the impact is obviously not as severe)


==== and test results ====
I can reproduce this on a regular basis, however it doesn't always cause the nfsd4_stateowners to rise when first running the test loop, and it results in something like this:
# while true ; do echo "$(date +'%F %T') - $(grep nfsd4_stateowners /proc/slabinfo)" ; sleep 5 ; done
2016-02-20 09:52:10 - nfsd4_stateowners 108297 108297    424    9    1 : tunables   54   27    8 : slabdata  12033  12033      0
2016-02-20 09:52:15 - nfsd4_stateowners 118620 118620    424    9    1 : tunables   54   27    8 : slabdata  13180  13180      0
2016-02-20 09:52:20 - nfsd4_stateowners 129024 129024    424    9    1 : tunables   54   27    8 : slabdata  14336  14336      0
2016-02-20 09:52:25 - nfsd4_stateowners 138609 138609    424    9    1 : tunables   54   27    8 : slabdata  15401  15401      0
2016-02-20 09:52:30 - nfsd4_stateowners   4608   4608    424    9    1 : tunables   54   27    8 : slabdata    512    512      0
2016-02-20 09:52:35 - nfsd4_stateowners  20646  20646    424    9    1 : tunables   54   27    8 : slabdata   2294   2294      0
2016-02-20 09:52:40 - nfsd4_stateowners  35802  35802    424    9    1 : tunables   54   27    8 : slabdata   3978   3978      0
2016-02-20 09:52:45 - nfsd4_stateowners  49914  49914    424    9    1 : tunables   54   27    8 : slabdata   5546   5546      0
2016-02-20 09:52:50 - nfsd4_stateowners  63873  63873    424    9    1 : tunables   54   27    8 : slabdata   7097   7097      0
2016-02-20 09:52:55 - nfsd4_stateowners  76176  76176    424    9    1 : tunables   54   27    8 : slabdata   8464   8464      0
2016-02-20 09:53:00 - nfsd4_stateowners  87858  87858    424    9    1 : tunables   54   27    8 : slabdata   9762   9762      0
2016-02-20 09:53:05 - nfsd4_stateowners  99207  99207    424    9    1 : tunables   54   27    8 : slabdata  11023  11023      0
2016-02-20 09:53:10 - nfsd4_stateowners 109674 109674    424    9    1 : tunables   54   27    8 : slabdata  12186  12186      0
2016-02-20 09:53:15 - nfsd4_stateowners 119394 119394    424    9    1 : tunables   54   27    8 : slabdata  13266  13266      0
2016-02-20 09:53:20 - nfsd4_stateowners 129582 129582    424    9    1 : tunables   54   27    8 : slabdata  14398  14398      0
2016-02-20 09:53:25 - nfsd4_stateowners 139698 139698    424    9    1 : tunables   54   27    8 : slabdata  15522  15522      0
2016-02-20 09:53:30 - nfsd4_stateowners   5211   5211    424    9    1 : tunables   54   27    8 : slabdata    579    579      0
2016-02-20 09:53:35 - nfsd4_stateowners  20529  20529    424    9    1 : tunables   54   27    8 : slabdata   2281   2281      0
2016-02-20 09:53:40 - nfsd4_stateowners  35406  35406    424    9    1 : tunables   54   27    8 : slabdata   3934   3934      0
2016-02-20 09:53:45 - nfsd4_stateowners  49635  49635    424    9    1 : tunables   54   27    8 : slabdata   5515   5515      0
2016-02-20 09:53:51 - nfsd4_stateowners  63225  63225    424    9    1 : tunables   54   27    8 : slabdata   7025   7025      0

This sawtooth seems to behave just fine.  However after running several of the loops simultaneously, something changes, and nfsd4_stateowners begins growing, even after killing off all the clients:
for example, here is a steady state after the number of nfsd4_stateowners grows, and I've killed off all the loops causing the issue (6.7 kernel):
2016-02-20 10:41:21 - nfsd4_stateowners 340617 340623    424    9    1 : tunables   54   27    8 : slabdata  37847  37847      0
2016-02-20 10:41:26 - nfsd4_stateowners 340617 340623    424    9    1 : tunables   54   27    8 : slabdata  37847  37847      0
2016-02-20 10:41:31 - nfsd4_stateowners 340617 340623    424    9    1 : tunables   54   27    8 : slabdata  37847  37847      0
2016-02-20 10:41:36 - nfsd4_stateowners 340617 340623    424    9    1 : tunables   54   27    8 : slabdata  37847  37847      0

on a RHEL 5.11 box I start one of these: # su - user2 -c "/bin/bash -c 'while true ; do echo test >> /mnt/vm15/user1_files/test_file.3 ; done 2>/dev/null'"
2016-02-20 10:49:39 - nfsd4_stateowners 346032 346032    424    9    1 : tunables   54   27    8 : slabdata  38448  38448      0
2016-02-20 10:49:44 - nfsd4_stateowners 351540 351540    424    9    1 : tunables   54   27    8 : slabdata  39060  39060      0
2016-02-20 10:49:49 - nfsd4_stateowners 357156 357156    424    9    1 : tunables   54   27    8 : slabdata  39684  39684      0
2016-02-20 10:49:54 - nfsd4_stateowners 363501 363501    424    9    1 : tunables   54   27    8 : slabdata  40389  40389      0
I kill off the loop on the nfs client, and the count levels off:
2016-02-20 10:49:59 - nfsd4_stateowners 366496 366498    424    9    1 : tunables   54   27    8 : slabdata  40722  40722      0
2016-02-20 10:50:04 - nfsd4_stateowners 366495 366498    424    9    1 : tunables   54   27    8 : slabdata  40722  40722      0
2016-02-20 10:50:10 - nfsd4_stateowners 366495 366498    424    9    1 : tunables   54   27    8 : slabdata  40722  40722      0
start it back up again:
2016-02-20 10:57:38 - nfsd4_stateowners 366495 366498    424    9    1 : tunables   54   27    8 : slabdata  40722  40722      0
2016-02-20 10:57:43 - nfsd4_stateowners 370476 370476    424    9    1 : tunables   54   27    8 : slabdata  41164  41164      0
2016-02-20 10:57:48 - nfsd4_stateowners 376317 376317    424    9    1 : tunables   54   27    8 : slabdata  41813  41813      0
2016-02-20 10:57:53 - nfsd4_stateowners 382158 382158    424    9    1 : tunables   54   27    8 : slabdata  42462  42462      0
...
2016-02-20 11:03:50 - nfsd4_stateowners 716490 716490    424    9    1 : tunables   54   27    8 : slabdata  79610  79610      0
2016-02-20 11:03:55 - nfsd4_stateowners 721107 721107    424    9    1 : tunables   54   27    8 : slabdata  80123  80123      0
2016-02-20 11:04:00 - nfsd4_stateowners 725661 725661    424    9    1 : tunables   54   27    8 : slabdata  80629  80629      0


The results with the patched kernel look good:
=====
# uname -r
2.6.32-573.20.1.el6.x86_64

# grep nfsd4_stateowners /proc/slabinfo 
nfsd4_stateowners 150768 150768    424    9    1 : tunables   54   27    8 : slabdata  16752  16752      0

=====
# uname -r
2.6.32-573.7.1.el6.bugs/rhbz1300006.1.x86_64

# grep nfsd4_stateowners /proc/slabinfo 
nfsd4_stateowners      9      9    424    9    1 : tunables   54   27    8 : slabdata	   1	  1	 0

=====
# grep nfsd4_stateowners /proc/slabinfo 
nfsd4_stateowners      1      9    424    9    1 : tunables   54   27    8 : slabdata      1      1      0

# uname -r
2.6.32-616.el6.bugs/rhbz1300006.1.x86_64

